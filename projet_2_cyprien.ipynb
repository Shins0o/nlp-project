{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import csv \n",
    "from selenium import webdriver\n",
    "import time\n",
    "import sys\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper.PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python scraper.py -i --url \"https://www.tripadvisor.com/Restaurants-g186338-London_England.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GithHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main e085330] Adding Cyprien'Notebook\n",
      " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
      " create mode 100644 chromedriver.exe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/Shins0o/nlp-project\n",
      "   a7ce22e..e085330  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://uk.trustpilot.com/categories/restaurants_bars?location=London&trustscore=4.5&verified=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeRestaurantsUrls(tripURLs):\n",
    "    urls =[]\n",
    "    for url in tripURLs:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "        results = soup.find('div', class_='_1kXteagE')\n",
    "        stores = results.find_all('div', class_='wQjYiB7z')\n",
    "        for store in stores:\n",
    "            unModifiedUrl = str(store.find('a', href=True)['href'])\n",
    "            urls.append('https://www.tripadvisor.com'+unModifiedUrl)            \n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeRestaurantsUrls(url):\n",
    "    print(\"entering first function\")\n",
    "    urls =[]\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    # print(soup)\n",
    "    # results = soup.find('div', class_='_1kXteagE')\n",
    "    stores = soup.find_all('div', class_='wQjYiB7z')\n",
    "    for store in stores:\n",
    "        unModifiedUrl = str(store.find('a', href=True)['href'])\n",
    "        urls.append('https://www.tripadvisor.com'+unModifiedUrl)  \n",
    "    print('urls : ',urls)          \n",
    "    return urls\n",
    "\n",
    "def scrapeRestaurantInfo(url):\n",
    "    print(url)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    storeName = soup.find('h1', class_='_3a1XQ88S').text\n",
    "    avgRating = soup.find('span', class_='r2Cf69qf').text.strip()\n",
    "    storeAddress = soup.find('div', class_= '_2vbD36Hr _36TL14Jn').find('span', class_='_2saB_OSe').text.strip()\n",
    "    noReviews = soup.find('a', class_='_10Iv7dOs').text.strip().split()[0]\n",
    "    print(storeName)\n",
    "    with open(pathToStoreInfo, mode='a', encoding=\"utf-8\") as trip:\n",
    "        data_writer = csv.writer(trip, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "        data_writer.writerow([storeName, storeAddress, avgRating, noReviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-c767e84702da>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Edge('msedgedriver.exe')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "entering first function\n"
     ]
    }
   ],
   "source": [
    "startingurl = \"https://www.tripadvisor.com/Restaurants-g186338-London_England.html\"\n",
    "driver = webdriver.Edge('msedgedriver.exe')\n",
    "# driver.get(url)\n",
    "print(\"starting\")\n",
    "urls = scrapeRestaurantsUrls(startingurl)\n",
    "for url in urls:\n",
    "    print(url)\n",
    "    #if you want to scrape restaurants info\n",
    "    if info == True:\n",
    "        scrapeRestaurantInfo(url)\n",
    "\n",
    "    nextPage = True\n",
    "    while nextPage:\n",
    "        #Requests\n",
    "        driver.get(url)\n",
    "        time.sleep(1)\n",
    "        #Click More button\n",
    "        more = driver.find_elements_by_xpath(\"//span[contains(text(),'More')]\")\n",
    "        for x in range(0,len(more)):\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].click();\", more[x])\n",
    "                time.sleep(3)\n",
    "            except:\n",
    "                pass\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        #Store name\n",
    "        storeName = soup.find('h1', class_='_3a1XQ88S').text\n",
    "        #Reviews\n",
    "        results = soup.find('div', class_='listContainer hide-more-mobile')\n",
    "        try:\n",
    "            reviews = results.find_all('div', class_='prw_rup prw_reviews_review_resp')\n",
    "        except Exception:\n",
    "            continue\n",
    "        #Export to csv\n",
    "        try:\n",
    "            with open(pathToReviews, mode='a', encoding=\"utf-8\") as trip_data:\n",
    "                data_writer = csv.writer(trip_data, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "                for review in reviews:\n",
    "                    ratingDate = review.find('span', class_='ratingDate').get('title')\n",
    "                    text_review = review.find('p', class_='partial_entry')\n",
    "                    if len(text_review.contents) > 2:\n",
    "                        reviewText = str(text_review.contents[0][:-3]) + ' ' + str(text_review.contents[1].text)\n",
    "                    else:\n",
    "                        reviewText = text_review.text\n",
    "                    reviewerUsername = review.find('div', class_='info_text pointer_cursor')\n",
    "                    reviewerUsername = reviewerUsername.select('div > div')[0].get_text(strip=True)\n",
    "                    rating = review.find('div', class_='ui_column is-9').findChildren('span')\n",
    "                    rating = str(rating[0]).split('_')[3].split('0')[0]\n",
    "                    data_writer.writerow([storeName, reviewerUsername, ratingDate, reviewText, rating])\n",
    "        except:\n",
    "            pass\n",
    "        #Go to next page if exists\n",
    "        try:\n",
    "            unModifiedUrl = str(soup.find('a', class_ = 'nav next ui_button primary',href=True)['href'])\n",
    "            url = 'https://www.tripadvisor.com' + unModifiedUrl\n",
    "        except:\n",
    "            nextPage = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
