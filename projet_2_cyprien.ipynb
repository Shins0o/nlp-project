{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import csv \n",
    "from selenium import webdriver\n",
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraper.PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python scraper.py -i --url \"https://www.tripadvisor.com/Restaurants-g186338-London_England.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GithHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cyprien\\OneDrive - De Vinci\\Documents\\ESILV\\A5\\Machine_Learning_NLP\\Project2\\nlp-project\n"
     ]
    }
   ],
   "source": [
    "cd \"C:\\Users\\Cyprien\\OneDrive - De Vinci\\Documents\\ESILV\\A5\\Machine_Learning_NLP\\Project2\\nlp-project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main a4aa8d1] modifications\n",
      " 4 files changed, 277 insertions(+), 1 deletion(-)\n",
      " create mode 100644 msedgedriver.exe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/Shins0o/nlp-project\n",
      " ! [rejected]        main -> main (fetch first)\n",
      "error: failed to push some refs to 'https://github.com/Shins0o/nlp-project'\n",
      "hint: Updates were rejected because the remote contains work that you do\n",
      "hint: not have locally. This is usually caused by another repository pushing\n",
      "hint: to the same ref. You may want to first integrate the remote changes\n",
      "hint: (e.g., 'git pull ...') before pushing again.\n",
      "hint: See the 'Note about fast-forwards' in 'git push --help' for details.\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"modifications\"\n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url = \"https://uk.trustpilot.com/categories/restaurants_bars?location=London&trustscore=4.5&verified=true\" # 4.5 stars london food\n",
    "# url = \"https://uk.trustpilot.com/categories/restaurants_bars?location=London&trustscore=4.0&verified=true\" # +4 stars london food\n",
    "\n",
    "url = \"https://uk.trustpilot.com/categories/restaurant?sort=reviews_count\" # All UK restaurants\n",
    "# url = \"https://uk.trustpilot.com/categories/restaurant?location=London&sort=reviews_count\" # All London Restaurants\n",
    "urls =[]\n",
    "nextPage = True\n",
    "while nextPage:\n",
    "    page = requests.get(url)\n",
    "    time.sleep(1)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    restaurant_links = soup.find_all('a', {'data-business-unit-card-link': 'true'})\n",
    "    for link in restaurant_links:\n",
    "        href = link.get('href')\n",
    "        urls.append(\"https://uk.trustpilot.com\"+href)  \n",
    "    \n",
    "    # Restaurants are ordered in nnumber of reviews so we stop the loop if we find a restaurant without review : the next pages won't\n",
    "    # try:\n",
    "    #     soup.find('div', class_ = \"styles_rating__pY5Pk\")\n",
    "    # except: \n",
    "    #     break \n",
    "\n",
    "    # Go to next page or stop the loop if at the last page\n",
    "    try:\n",
    "        href = str(soup.find('a',{'aria-label':\"Next page\"})['href'])\n",
    "        url = 'https://uk.trustpilot.com/' + href\n",
    "    except:\n",
    "        nextPage = False\n",
    "\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For one restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='uk.trustpilot.com', port=443): Max retries exceeded with url: /review/dineindulge.co.uk (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000024731B05250>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             conn = connection.create_connection(\n\u001b[0m\u001b[0;32m    170\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    917\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             raise NewConnectionError(\n\u001b[0m\u001b[0;32m    182\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x0000024731B05250>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m             resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m             retries = retries.increment(\n\u001b[0m\u001b[0;32m    756\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='uk.trustpilot.com', port=443): Max retries exceeded with url: /review/dineindulge.co.uk (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000024731B05250>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-f65eb78da245>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnextPage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mnextPage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"get\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    587\u001b[0m         }\n\u001b[0;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Cyprien\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    517\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='uk.trustpilot.com', port=443): Max retries exceeded with url: /review/dineindulge.co.uk (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x0000024731B05250>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "test = \"restaurant_reviews.csv\"\n",
    "\n",
    "url = \"https://uk.trustpilot.com/review/dineindulge.co.uk\"\n",
    "# reviews = []\n",
    "# for url in urls :\n",
    "nextPage = True\n",
    "while nextPage:\n",
    "    page = requests.get(url)\n",
    "    time.sleep(0.3)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    # Information about the restaurant\n",
    "    avg_rating = soup.find('p',class_=\"typography_body-l__KUYFJ typography_appearance-subtle__8_H2l\").text\n",
    "    restaurant_name = soup.find('span', class_='typography_display-s__qOjh6 typography_appearance-default__AAY17 title_displayName__TtDDM').contents[0] # not .text to take only what's before  <!-- -->'\n",
    "    categories_element = soup.find_all('a',class_=\"link_internal__7XN06 typography_appearance-action__9NNRY link_link__IZzHN link_underlined__OXYVM\")\n",
    "    categories = []\n",
    "    for element in categories_element :\n",
    "        category  = element.text\n",
    "        if category not in categories:\n",
    "            categories.append(category)\n",
    "    information = soup.find('div', class_='styles_container__9nZxD customer-generated-content').text\n",
    "\n",
    "    # Putting informations about the reviews in a csv file\n",
    "    try:\n",
    "        with open(test, mode='a', encoding=\"utf-8\") as trip_data:\n",
    "            data_writer = csv.writer(trip_data, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "            # Writing column headers as the first row\n",
    "            data_writer.writerow(['Rating', 'Restaurant Name', 'Categories', 'Average Rating', 'Experience Date', 'Username', 'Review Title', 'Information', 'Review Text'])\n",
    "            # retrieving reviews\n",
    "            reviews_elements = soup.find_all('article', class_=\"paper_paper__1PY90 paper_outline__lwsUX card_card__lQWDv card_noPadding__D8PcU styles_reviewCard__hcAvl\")\n",
    "            #retrieving info within reviews\n",
    "            for review in reviews_elements :\n",
    "                experience_date = review.find('p', class_=\"typography_body-m__xgxZ_ typography_appearance-default__AAY17\").text.strip().split(\":\")[-1].strip()\n",
    "                experience_date = datetime.strptime(experience_date, '%d %B %Y')\n",
    "                experience_date = experience_date.strftime(\"%Y-%m-%d\")\n",
    "                review_username = review.find('span', class_=\"typography_heading-xxs__QKBS8 typography_appearance-default__AAY17\").text\n",
    "                if review.find('img', {'alt':'Rated 5 out of 5 stars'}):\n",
    "                    rating = 5\n",
    "                elif review.find('img', {'alt':'Rated 4 out of 5 stars'}):\n",
    "                    rating = 4\n",
    "                elif review.find('img', {'alt':'Rated 3 out of 5 stars'}):\n",
    "                    rating = 3\n",
    "                elif review.find('img', {'alt':'Rated 2 out of 5 stars'}):\n",
    "                    rating = 2\n",
    "                elif review.find('img', {'alt':'Rated 1 out of 5 stars'}):\n",
    "                    rating = 1\n",
    "                elif review.find('img', {'alt':'Rated 0 out of 5 stars'}):\n",
    "                    rating = 0\n",
    "                review_title = review.find('h2', class_=\"typography_heading-s__f7029 typography_appearance-default__AAY17\").text\n",
    "                try:\n",
    "                    review_text = review.find('p', class_=\"typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn\").text\n",
    "                except:\n",
    "                    review_text = '' # to treat it more efficiently during NLP preprocessing\n",
    "                # reviews.append([rating, experience_date, review_username, review_title, review_text])\n",
    "                data_writer.writerow([rating, restaurant_name, categories, avg_rating,  experience_date, review_username, review_title, information, review_text])\n",
    "    except:\n",
    "        print(\"passed\")\n",
    "    try:\n",
    "        href = str(soup.find('a',{'aria-label':\"Next page\"})['href'])\n",
    "        url = 'https://uk.trustpilot.com/' + href\n",
    "    except:\n",
    "        nextPage = False\n",
    "\n",
    "# reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For all restaurant from London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_london_reviews = \"restaurant_london_reviews.csv\"\n",
    "with open(restaurant_london_reviews, mode='a', encoding=\"utf-8\") as review_data:\n",
    "    data_writer = csv.writer(review_data, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    # Writing column headers as the first row\n",
    "    data_writer.writerow(['Rating', 'Restaurant Name', 'Categories', 'Average Rating', 'Experience Date', 'Username', 'Review Title', 'Information', 'Review Text'])\n",
    "\n",
    "for url in urls :\n",
    "    nextPage = True\n",
    "    while nextPage:\n",
    "        page = requests.get(url)\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        # Information about the restaurant\n",
    "        avg_rating = soup.find('p',class_=\"typography_body-l__KUYFJ typography_appearance-subtle__8_H2l\").text\n",
    "        restaurant_name = soup.find('span', class_='typography_display-s__qOjh6 typography_appearance-default__AAY17 title_displayName__TtDDM').contents[0] # not .text to take only what's before  <!-- -->'\n",
    "        categories_element = soup.find_all('a',class_=\"link_internal__7XN06 typography_appearance-action__9NNRY link_link__IZzHN link_underlined__OXYVM\")\n",
    "        categories = []\n",
    "        for element in categories_element :\n",
    "            category  = element.text\n",
    "            if category not in categories:\n",
    "                categories.append(category)\n",
    "        try: #not all restaurants have filled info\n",
    "            information = soup.find('div', class_='styles_container__9nZxD customer-generated-content').text\n",
    "        except:\n",
    "            information = ''\n",
    "\n",
    "        # Putting informations about the reviews in a csv file\n",
    "        try:\n",
    "            with open(restaurant_london_reviews, mode='a', encoding=\"utf-8\") as review_data:\n",
    "                data_writer = csv.writer(review_data, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "                # retrieving reviews\n",
    "                reviews_elements = soup.find_all('article', class_=\"paper_paper__1PY90 paper_outline__lwsUX card_card__lQWDv card_noPadding__D8PcU styles_reviewCard__hcAvl\")\n",
    "                #retrieving info within reviews\n",
    "                for review in reviews_elements :\n",
    "                    experience_date = review.find('p', class_=\"typography_body-m__xgxZ_ typography_appearance-default__AAY17\").text.strip().split(\":\")[-1].strip()\n",
    "                    experience_date = datetime.strptime(experience_date, '%d %B %Y')\n",
    "                    experience_date = experience_date.strftime(\"%Y-%m-%d\")\n",
    "                    review_username = review.find('span', class_=\"typography_heading-xxs__QKBS8 typography_appearance-default__AAY17\").text\n",
    "                    if review.find('img', {'alt':'Rated 5 out of 5 stars'}):\n",
    "                        rating = 5\n",
    "                    elif review.find('img', {'alt':'Rated 4 out of 5 stars'}):\n",
    "                        rating = 4\n",
    "                    elif review.find('img', {'alt':'Rated 3 out of 5 stars'}):\n",
    "                        rating = 3\n",
    "                    elif review.find('img', {'alt':'Rated 2 out of 5 stars'}):\n",
    "                        rating = 2\n",
    "                    elif review.find('img', {'alt':'Rated 1 out of 5 stars'}):\n",
    "                        rating = 1\n",
    "                    elif review.find('img', {'alt':'Rated 0 out of 5 stars'}):\n",
    "                        rating = 0\n",
    "                    review_title = review.find('h2', class_=\"typography_heading-s__f7029 typography_appearance-default__AAY17\").text\n",
    "                    try:\n",
    "                        review_text = review.find('p', class_=\"typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn\").text\n",
    "                    except:\n",
    "                        review_text = '' # to treat it more efficiently during NLP preprocessing\n",
    "                    data_writer.writerow([rating, restaurant_name, categories, avg_rating,  experience_date, review_username, review_title, information, review_text])\n",
    "        except:\n",
    "            print(\"passed\")\n",
    "        try:\n",
    "            href = str(soup.find('a',{'aria-label':\"Next page\"})['href'])\n",
    "            url = 'https://uk.trustpilot.com/' + href\n",
    "        except:\n",
    "            nextPage = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For all UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_uk_reviews = \"restaurant_uk_reviews.csv\"\n",
    "with open(restaurant_uk_reviews, mode='a', encoding=\"utf-8\") as review_data:\n",
    "    data_writer = csv.writer(review_data, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    # Writing column headers as the first row\n",
    "    data_writer.writerow(['Rating', 'Restaurant Name', 'Categories', 'Average Rating', 'Experience Date', 'Username', 'Review Title', 'Information', 'Review Text'])\n",
    "\n",
    "for url in urls :\n",
    "    nextPage = True\n",
    "    while nextPage:\n",
    "        page = requests.get(url)\n",
    "        time.sleep(0.3)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        # Information about the restaurant\n",
    "        try:\n",
    "            avg_rating = soup.find('p',class_=\"typography_body-l__KUYFJ typography_appearance-subtle__8_H2l\").text\n",
    "        except:\n",
    "            break\n",
    "        restaurant_name = soup.find('span', class_='typography_display-s__qOjh6 typography_appearance-default__AAY17 title_displayName__TtDDM').contents[0] # not .text to take only what's before  <!-- -->'\n",
    "        categories_element = soup.find_all('a',class_=\"link_internal__7XN06 typography_appearance-action__9NNRY link_link__IZzHN link_underlined__OXYVM\")\n",
    "        categories = []\n",
    "        for element in categories_element :\n",
    "            category  = element.text\n",
    "            if category not in categories:\n",
    "                categories.append(category)\n",
    "        try: #not all restaurants have filled info\n",
    "            information = soup.find('div', class_='styles_container__9nZxD customer-generated-content').text\n",
    "        except:\n",
    "            information = ''\n",
    "\n",
    "        # Putting informations about the reviews in a csv file\n",
    "        try:\n",
    "            with open(restaurant_uk_reviews, mode='a', encoding=\"utf-8\") as review_data:\n",
    "                data_writer = csv.writer(review_data, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "                # retrieving reviews\n",
    "                reviews_elements = soup.find_all('article', class_=\"paper_paper__1PY90 paper_outline__lwsUX card_card__lQWDv card_noPadding__D8PcU styles_reviewCard__hcAvl\")\n",
    "                #retrieving info within reviews\n",
    "                for review in reviews_elements :\n",
    "                    experience_date = review.find('p', class_=\"typography_body-m__xgxZ_ typography_appearance-default__AAY17\").text.strip().split(\":\")[-1].strip()\n",
    "                    experience_date = datetime.strptime(experience_date, '%d %B %Y')\n",
    "                    experience_date = experience_date.strftime(\"%Y-%m-%d\")\n",
    "                    review_username = review.find('span', class_=\"typography_heading-xxs__QKBS8 typography_appearance-default__AAY17\").text\n",
    "                    if review.find('img', {'alt':'Rated 5 out of 5 stars'}):\n",
    "                        rating = 5\n",
    "                    elif review.find('img', {'alt':'Rated 4 out of 5 stars'}):\n",
    "                        rating = 4\n",
    "                    elif review.find('img', {'alt':'Rated 3 out of 5 stars'}):\n",
    "                        rating = 3\n",
    "                    elif review.find('img', {'alt':'Rated 2 out of 5 stars'}):\n",
    "                        rating = 2\n",
    "                    elif review.find('img', {'alt':'Rated 1 out of 5 stars'}):\n",
    "                        rating = 1\n",
    "                    elif review.find('img', {'alt':'Rated 0 out of 5 stars'}):\n",
    "                        rating = 0\n",
    "                    review_title = review.find('h2', class_=\"typography_heading-s__f7029 typography_appearance-default__AAY17\").text\n",
    "                    try:\n",
    "                        review_text = review.find('p', class_=\"typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn\").text\n",
    "                    except:\n",
    "                        review_text = '' # to treat it more efficiently during NLP preprocessing\n",
    "                    data_writer.writerow([rating, restaurant_name, categories, avg_rating,  experience_date, review_username, review_title, information, review_text])\n",
    "        except:\n",
    "            print(\"passed\")\n",
    "        try:\n",
    "            href = str(soup.find('a',{'aria-label':\"Next page\"})['href'])\n",
    "            url = 'https://uk.trustpilot.com/' + href\n",
    "        except:\n",
    "            nextPage = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Average Rating</th>\n",
       "      <th>Experience Date</th>\n",
       "      <th>Username</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Information</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rating</td>\n",
       "      <td>Restaurant Name</td>\n",
       "      <td>Categories</td>\n",
       "      <td>Average Rating</td>\n",
       "      <td>Experience Date</td>\n",
       "      <td>Username</td>\n",
       "      <td>Review Title</td>\n",
       "      <td>Information</td>\n",
       "      <td>Review Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Franco Manca</td>\n",
       "      <td>['Restaurant']</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2024-01-13</td>\n",
       "      <td>Sima Nava</td>\n",
       "      <td>Rude and unfair treatment</td>\n",
       "      <td>Franco Manca - Sourdough Pizza. The pizza is m...</td>\n",
       "      <td>The waiter was terribly rude, I visited here o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Franco Manca</td>\n",
       "      <td>['Restaurant']</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2024-01-13</td>\n",
       "      <td>Aidy</td>\n",
       "      <td>Appalling service from staff at Exeter branch.</td>\n",
       "      <td>Franco Manca - Sourdough Pizza. The pizza is m...</td>\n",
       "      <td>Took my girlfriend to Franco Manca Exeter bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Franco Manca</td>\n",
       "      <td>['Restaurant']</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2024-01-10</td>\n",
       "      <td>O P</td>\n",
       "      <td>Manager was rude</td>\n",
       "      <td>Franco Manca - Sourdough Pizza. The pizza is m...</td>\n",
       "      <td>Wimbledon Branch- Manager was rude. Refused to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Franco Manca</td>\n",
       "      <td>['Restaurant']</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>Tommy Andrews</td>\n",
       "      <td>Awful - St Paul’s branch</td>\n",
       "      <td>Franco Manca - Sourdough Pizza. The pizza is m...</td>\n",
       "      <td>Awful, rude and disgraceful service from a fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>Rating</td>\n",
       "      <td>Restaurant Name</td>\n",
       "      <td>Categories</td>\n",
       "      <td>Average Rating</td>\n",
       "      <td>Experience Date</td>\n",
       "      <td>Username</td>\n",
       "      <td>Review Title</td>\n",
       "      <td>Information</td>\n",
       "      <td>Review Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>Rating</td>\n",
       "      <td>Restaurant Name</td>\n",
       "      <td>Categories</td>\n",
       "      <td>Average Rating</td>\n",
       "      <td>Experience Date</td>\n",
       "      <td>Username</td>\n",
       "      <td>Review Title</td>\n",
       "      <td>Information</td>\n",
       "      <td>Review Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>Rating</td>\n",
       "      <td>Restaurant Name</td>\n",
       "      <td>Categories</td>\n",
       "      <td>Average Rating</td>\n",
       "      <td>Experience Date</td>\n",
       "      <td>Username</td>\n",
       "      <td>Review Title</td>\n",
       "      <td>Information</td>\n",
       "      <td>Review Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>Rating</td>\n",
       "      <td>Restaurant Name</td>\n",
       "      <td>Categories</td>\n",
       "      <td>Average Rating</td>\n",
       "      <td>Experience Date</td>\n",
       "      <td>Username</td>\n",
       "      <td>Review Title</td>\n",
       "      <td>Information</td>\n",
       "      <td>Review Text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>Rating</td>\n",
       "      <td>Restaurant Name</td>\n",
       "      <td>Categories</td>\n",
       "      <td>Average Rating</td>\n",
       "      <td>Experience Date</td>\n",
       "      <td>Username</td>\n",
       "      <td>Review Title</td>\n",
       "      <td>Information</td>\n",
       "      <td>Review Text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>776 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rating  Restaurant Name      Categories  Average Rating  Experience Date  \\\n",
       "0    Rating  Restaurant Name      Categories  Average Rating  Experience Date   \n",
       "1         1     Franco Manca  ['Restaurant']             2.7       2024-01-13   \n",
       "2         2     Franco Manca  ['Restaurant']             2.7       2024-01-13   \n",
       "3         1     Franco Manca  ['Restaurant']             2.7       2024-01-10   \n",
       "4         1     Franco Manca  ['Restaurant']             2.7       2023-12-23   \n",
       "..      ...              ...             ...             ...              ...   \n",
       "771  Rating  Restaurant Name      Categories  Average Rating  Experience Date   \n",
       "772  Rating  Restaurant Name      Categories  Average Rating  Experience Date   \n",
       "773  Rating  Restaurant Name      Categories  Average Rating  Experience Date   \n",
       "774  Rating  Restaurant Name      Categories  Average Rating  Experience Date   \n",
       "775  Rating  Restaurant Name      Categories  Average Rating  Experience Date   \n",
       "\n",
       "          Username                                    Review Title  \\\n",
       "0         Username                                    Review Title   \n",
       "1        Sima Nava                       Rude and unfair treatment   \n",
       "2             Aidy  Appalling service from staff at Exeter branch.   \n",
       "3              O P                                Manager was rude   \n",
       "4    Tommy Andrews                        Awful - St Paul’s branch   \n",
       "..             ...                                             ...   \n",
       "771       Username                                    Review Title   \n",
       "772       Username                                    Review Title   \n",
       "773       Username                                    Review Title   \n",
       "774       Username                                    Review Title   \n",
       "775       Username                                    Review Title   \n",
       "\n",
       "                                           Information  \\\n",
       "0                                          Information   \n",
       "1    Franco Manca - Sourdough Pizza. The pizza is m...   \n",
       "2    Franco Manca - Sourdough Pizza. The pizza is m...   \n",
       "3    Franco Manca - Sourdough Pizza. The pizza is m...   \n",
       "4    Franco Manca - Sourdough Pizza. The pizza is m...   \n",
       "..                                                 ...   \n",
       "771                                        Information   \n",
       "772                                        Information   \n",
       "773                                        Information   \n",
       "774                                        Information   \n",
       "775                                        Information   \n",
       "\n",
       "                                           Review Text  \n",
       "0                                          Review Text  \n",
       "1    The waiter was terribly rude, I visited here o...  \n",
       "2    Took my girlfriend to Franco Manca Exeter bran...  \n",
       "3    Wimbledon Branch- Manager was rude. Refused to...  \n",
       "4    Awful, rude and disgraceful service from a fra...  \n",
       "..                                                 ...  \n",
       "771                                        Review Text  \n",
       "772                                        Review Text  \n",
       "773                                        Review Text  \n",
       "774                                        Review Text  \n",
       "775                                        Review Text  \n",
       "\n",
       "[776 rows x 9 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl = pd.read_csv('restaurant_london_reviews.csv')\n",
    "dfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating             object\n",
       "Restaurant Name    object\n",
       "Categories         object\n",
       "Average Rating     object\n",
       "Experience Date    object\n",
       "Username           object\n",
       "Review Title       object\n",
       "Information        object\n",
       "Review Text        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating              0\n",
       "Restaurant Name     0\n",
       "Categories          0\n",
       "Average Rating      0\n",
       "Experience Date     0\n",
       "Username            0\n",
       "Review Title        0\n",
       "Information         0\n",
       "Review Text        18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfl.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Average Rating</th>\n",
       "      <th>Experience Date</th>\n",
       "      <th>Username</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Information</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Buyagift</td>\n",
       "      <td>['Hotel', 'Adventure Sports', 'Racetrack', 'Co...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2023-12-24</td>\n",
       "      <td>SUE CHAPMAN</td>\n",
       "      <td>Good choice and reasonable prices</td>\n",
       "      <td>Buyagift is the UK's leading provider of gift ...</td>\n",
       "      <td>The experience vouchers are easy to buy and a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Buyagift</td>\n",
       "      <td>['Hotel', 'Adventure Sports', 'Racetrack', 'Co...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2023-12-30</td>\n",
       "      <td>J. Cepson</td>\n",
       "      <td>Enjoy a lovely meal with our date night voucher</td>\n",
       "      <td>Buyagift is the UK's leading provider of gift ...</td>\n",
       "      <td>We were bought a Buyagift voucher for Christma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Buyagift</td>\n",
       "      <td>['Hotel', 'Adventure Sports', 'Racetrack', 'Co...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>sue</td>\n",
       "      <td>Experience was a little disappointing</td>\n",
       "      <td>Buyagift is the UK's leading provider of gift ...</td>\n",
       "      <td>Experience was a little disappointing, as the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Buyagift</td>\n",
       "      <td>['Hotel', 'Adventure Sports', 'Racetrack', 'Co...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2024-01-10</td>\n",
       "      <td>Mrs P</td>\n",
       "      <td>Perfect all through process 👍</td>\n",
       "      <td>Buyagift is the UK's leading provider of gift ...</td>\n",
       "      <td>Recently bought an afternoon tea voucher as a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Buyagift</td>\n",
       "      <td>['Hotel', 'Adventure Sports', 'Racetrack', 'Co...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>Yvonne Meechan</td>\n",
       "      <td>Treatments were excellent however…</td>\n",
       "      <td>Buyagift is the UK's leading provider of gift ...</td>\n",
       "      <td>Treatments were excellent however having to pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12313</th>\n",
       "      <td>5</td>\n",
       "      <td>Langstone Manor Holiday Park</td>\n",
       "      <td>['Camping Shop']</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2022-07-09</td>\n",
       "      <td>Liam Perry</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Set amongst delightful mature grounds in a she...</td>\n",
       "      <td>We had a fantastic time here recently having u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12314</th>\n",
       "      <td>5</td>\n",
       "      <td>DickHartley</td>\n",
       "      <td>['Restaurant']</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2022-06-16</td>\n",
       "      <td>John</td>\n",
       "      <td>Good to do business with.</td>\n",
       "      <td>Dick Hartley is an independent supplier of kit...</td>\n",
       "      <td>Good to do business with.Bought some Riedel gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12315</th>\n",
       "      <td>5</td>\n",
       "      <td>The Beachfield Hotel</td>\n",
       "      <td>['Family Hotel']</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2023-05-18</td>\n",
       "      <td>Bad Experience.</td>\n",
       "      <td>Clean ,competitive pricing,great food…</td>\n",
       "      <td>Welcome to Beachfield Hotel. We're a boutique ...</td>\n",
       "      <td>Clean ,competitive pricing,great food and staf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12316</th>\n",
       "      <td>5</td>\n",
       "      <td>Crofton and Park</td>\n",
       "      <td>['Jewellery Repair Service']</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2023-10-25</td>\n",
       "      <td>Poppy Khaisee-Headley</td>\n",
       "      <td>Excellent and professional service</td>\n",
       "      <td>A premium,personal concierge service.\\r\\n\\r\\nA...</td>\n",
       "      <td>Excellent and professional service. I had a di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12317</th>\n",
       "      <td>5</td>\n",
       "      <td>Haute Dolci Watford</td>\n",
       "      <td>['Dessert restaurant']</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2023-12-05</td>\n",
       "      <td>Jay</td>\n",
       "      <td>Dessert Heaven in Watford - 5 Stars!</td>\n",
       "      <td>Haute Dolci is a luxury dessert brand that off...</td>\n",
       "      <td>Haute Dolci in Watford is an absolute gem! If ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12318 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rating               Restaurant Name  \\\n",
       "0          5                      Buyagift   \n",
       "1          5                      Buyagift   \n",
       "2          3                      Buyagift   \n",
       "3          5                      Buyagift   \n",
       "4          3                      Buyagift   \n",
       "...      ...                           ...   \n",
       "12313      5  Langstone Manor Holiday Park   \n",
       "12314      5                   DickHartley   \n",
       "12315      5          The Beachfield Hotel   \n",
       "12316      5              Crofton and Park   \n",
       "12317      5           Haute Dolci Watford   \n",
       "\n",
       "                                              Categories Average Rating  \\\n",
       "0      ['Hotel', 'Adventure Sports', 'Racetrack', 'Co...            3.8   \n",
       "1      ['Hotel', 'Adventure Sports', 'Racetrack', 'Co...            3.8   \n",
       "2      ['Hotel', 'Adventure Sports', 'Racetrack', 'Co...            3.8   \n",
       "3      ['Hotel', 'Adventure Sports', 'Racetrack', 'Co...            3.8   \n",
       "4      ['Hotel', 'Adventure Sports', 'Racetrack', 'Co...            3.8   \n",
       "...                                                  ...            ...   \n",
       "12313                                   ['Camping Shop']            3.7   \n",
       "12314                                     ['Restaurant']            3.7   \n",
       "12315                                   ['Family Hotel']            3.7   \n",
       "12316                       ['Jewellery Repair Service']            3.7   \n",
       "12317                             ['Dessert restaurant']            3.7   \n",
       "\n",
       "      Experience Date               Username  \\\n",
       "0          2023-12-24            SUE CHAPMAN   \n",
       "1          2023-12-30             J. Cepson    \n",
       "2          2023-12-23                    sue   \n",
       "3          2024-01-10                  Mrs P   \n",
       "4          2024-01-11         Yvonne Meechan   \n",
       "...               ...                    ...   \n",
       "12313      2022-07-09             Liam Perry   \n",
       "12314      2022-06-16                   John   \n",
       "12315      2023-05-18        Bad Experience.   \n",
       "12316      2023-10-25  Poppy Khaisee-Headley   \n",
       "12317      2023-12-05                    Jay   \n",
       "\n",
       "                                          Review Title  \\\n",
       "0                    Good choice and reasonable prices   \n",
       "1      Enjoy a lovely meal with our date night voucher   \n",
       "2                Experience was a little disappointing   \n",
       "3                        Perfect all through process 👍   \n",
       "4                   Treatments were excellent however…   \n",
       "...                                                ...   \n",
       "12313                               Highly recommended   \n",
       "12314                        Good to do business with.   \n",
       "12315           Clean ,competitive pricing,great food…   \n",
       "12316               Excellent and professional service   \n",
       "12317             Dessert Heaven in Watford - 5 Stars!   \n",
       "\n",
       "                                             Information  \\\n",
       "0      Buyagift is the UK's leading provider of gift ...   \n",
       "1      Buyagift is the UK's leading provider of gift ...   \n",
       "2      Buyagift is the UK's leading provider of gift ...   \n",
       "3      Buyagift is the UK's leading provider of gift ...   \n",
       "4      Buyagift is the UK's leading provider of gift ...   \n",
       "...                                                  ...   \n",
       "12313  Set amongst delightful mature grounds in a she...   \n",
       "12314  Dick Hartley is an independent supplier of kit...   \n",
       "12315  Welcome to Beachfield Hotel. We're a boutique ...   \n",
       "12316  A premium,personal concierge service.\\r\\n\\r\\nA...   \n",
       "12317  Haute Dolci is a luxury dessert brand that off...   \n",
       "\n",
       "                                             Review Text  \n",
       "0      The experience vouchers are easy to buy and a ...  \n",
       "1      We were bought a Buyagift voucher for Christma...  \n",
       "2      Experience was a little disappointing, as the ...  \n",
       "3      Recently bought an afternoon tea voucher as a ...  \n",
       "4      Treatments were excellent however having to pa...  \n",
       "...                                                  ...  \n",
       "12313  We had a fantastic time here recently having u...  \n",
       "12314  Good to do business with.Bought some Riedel gl...  \n",
       "12315  Clean ,competitive pricing,great food and staf...  \n",
       "12316  Excellent and professional service. I had a di...  \n",
       "12317  Haute Dolci in Watford is an absolute gem! If ...  \n",
       "\n",
       "[12318 rows x 9 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfuk = pd.read_csv('restaurant_uk_reviews.csv')\n",
    "dfuk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            name  count\n",
      "0                       Buyagift   8280\n",
      "1               Zizzi Ristorante    571\n",
      "2                   Franco Manca    270\n",
      "3                    Dineindulge    260\n",
      "4                  Barmans.co.uk    180\n",
      "..                           ...    ...\n",
      "79  Langstone Manor Holiday Park      1\n",
      "80                   DickHartley      1\n",
      "81          The Beachfield Hotel      1\n",
      "82              Crofton and Park      1\n",
      "83           Haute Dolci Watford      1\n",
      "\n",
      "[84 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "value_counts = dfuk['Restaurant Name'].value_counts()\n",
    "result_df = value_counts.reset_index()\n",
    "result_df.columns = ['name', 'count']\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating             object\n",
       "Restaurant Name    object\n",
       "Categories         object\n",
       "Average Rating     object\n",
       "Experience Date    object\n",
       "Username           object\n",
       "Review Title       object\n",
       "Information        object\n",
       "Review Text        object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfuk.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating                0\n",
       "Restaurant Name       0\n",
       "Categories            0\n",
       "Average Rating        0\n",
       "Experience Date       0\n",
       "Username              0\n",
       "Review Title          0\n",
       "Information         349\n",
       "Review Text        1311\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfuk.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
